#!/usr/bin/env python3
from logger import get_logger
from models import get_conn
from jobs import enqueue_job,list_jobs,show_job,dlq_list,requeue_dlq,retry_job_force,worker_loop,show_status
import json  
import sys  
from multiprocessing import Process, Event
import time  
import argparse
import os 
import signal


logging = get_logger()
PID_FILE="./workers.pid"


def cmd_enqueue(args):
    job_id = enqueue_job(args.db,logging,command=args.command, job_json=args.json, max_retries=args.max_retries)
    print(job_id)

def cmd_list(args):
    rows = list_jobs(args.db,logging=logging,state=args.state, limit=args.limit)
    print(json.dumps(rows, indent=2, default=str))

def cmd_show(args):
    job = show_job(args.db, args.job_id)
    if not job:
        print(f"Job {args.job_id} not found", file=sys.stderr)
        sys.exit(2)
    print(json.dumps(job, indent=2, default=str))


def cmd_status(args):
    job = show_status(args.db,logger=logging)
    print(json.dumps(job, indent=2, default=str))


def cmd_dlq_list(args):
    rows = dlq_list(args.db, logger=logging,limit=args.limit)
    print(json.dumps(rows, indent=2, default=str))

def cmd_requeue_dlq(args):
    try:
        requeue_dlq(args.db,logging, args.job_id)
        print(f"Requeued {args.job_id}")
    except Exception as e:
        print(f"Error: {e}", file=sys.stderr)
        sys.exit(2)

def cmd_retry_job(args):
    try:
        retry_job_force(args.db,logging, args.job_id)
        print(f"Retry scheduled for {args.job_id}")
    except Exception as e:
        print(f"Error: {e}", file=sys.stderr)
        sys.exit(2)


def cmd_worker_stop(args):
    if not os.path.exists(PID_FILE):
        print("‚ö†Ô∏è No PID file found ‚Äî no workers to stop.")
        return

    with open(PID_FILE, "r") as f:
        pids = [int(line.strip()) for line in f if line.strip()]

    print(f"üõë Stopping {len(pids)} worker(s)...")

    for pid in pids:
        try:
            os.kill(pid, signal.SIGTERM)
            print(f"   ‚ûú Sent SIGTERM to PID {pid}")
        except ProcessLookupError:
            print(f"   ‚ö†Ô∏è Worker PID {pid} not found")

    os.remove(PID_FILE)
    print(" All workers stopped (gracefully signaled)")

def cmd_start_workers(args):
    # spawn worker processes and handle SIGINT to stop them


    stop_event = Event()
    processes = []
    logging.info(f"Starting {args.count} worker(s) (db={args.db})")
    try:
        for i in range(args.count):
            p = Process(target=worker_loop, args=(args.db, logging,stop_event, i, args.poll_interval), name=f"worker-{i}")
            p.start()
            processes.append(p)
        # main process waits until terminated
        while True:
            alive = any(p.is_alive() for p in processes)
            print(f" Saved worker PIDs to {PID_FILE}")
            time.sleep(1)
            if not alive:
                break
            time.sleep(0.5)
    except KeyboardInterrupt:
        logging.info("Shutdown requested, stopping workers...")
        stop_event.set()
        # give grace time
        for p in processes:
            p.join(timeout=5)
        logging.info("All workers stopped gracefully.")


def main():
    parser = argparse.ArgumentParser(description="queuectl - simple background job queue")
    subparsers = parser.add_subparsers(dest="subcommand")

    # Enqueue
    enqueue_parser = subparsers.add_parser("enqueue", help="Enqueue a new job")
    enqueue_parser.add_argument("--db", default="./queue.db", help="Path to queue database file")
    enqueue_parser.add_argument("--command", help="Command to run")
    enqueue_parser.add_argument("--max-retries", type=int, default=3, help="Max retries per job")
    enqueue_parser.add_argument("--json",help="Loads Json")

   

    # Start workers

    worker_parser = subparsers.add_parser("worker", help="Manage worker processes")
    worker_subparsers = worker_parser.add_subparsers(dest="action", required=True)
    worker_start_parser = worker_subparsers.add_parser("start", help="Start worker processes")
    worker_stop_parser = worker_subparsers.add_parser("stop", help="End worker processes")
    worker_start_parser.add_argument("--count", type=int, default=2, help="Number of worker processes")
    worker_start_parser.add_argument("--poll-interval", type=int, default=2, help="Polling interval (seconds)")
    worker_start_parser.add_argument("--db", default="./queue.db", help="Path to queue database file")
    

    # List jobs
    list_parser = subparsers.add_parser("list", help="List all jobs")
    list_parser.add_argument("--db", default="./queue.db", help="Path to queue database file")
    list_parser.add_argument("--state", default="running", help="Path to queue database file")
    list_parser.add_argument("--limit", default=10, help="Path to queue database file")


    status_parser= subparsers.add_parser("status",help="Helps in listing all jobs for now")
    status_parser.add_argument("--db", default="./queue.db", help="Path to queue database file")
    
    # Dead Letter Queue
    dlq_parser = subparsers.add_parser("dlq", help="Show Dead Letter Queue")
    sub_parser = dlq_parser.add_subparsers(dest="action")
    list_parser = sub_parser.add_parser("list",help="Lists all the DLQ queues")
    retry_parser = sub_parser.add_parser("retry",help="Retries the jobs by transfering to worker pool")
    retry_parser.add_argument("--job_id",help="Retries the specific job ID")
    dlq_parser.add_argument("--db", default="./queue.db", help="Path to queue database file")
    dlq_parser.add_argument("--limit", default=10, help="Path to queue database file")


    retry_parser= subparsers.add_parser("retry-job")
    retry_parser.add_argument("--db", default="./queue.db", help="Path to queue database file")
    retry_parser.add_argument("--job-id",default=0,help="The Job Id of the corresponding job")

    args = parser.parse_args()

    # Dispatch
    if args.subcommand == "enqueue":
        print(args.command)
        enqueue_job(db_path=args.db,logger=logging,command=args.command, max_retries=args.max_retries,job_json=args.json)
    elif args.subcommand == "worker":
        if args.action == "start":
            cmd_start_workers(args)
        elif args.action== "stop":
            cmd_worker_stop(args)
        else:
            parser.print_help()
    elif args.subcommand == "list":
        jobs = cmd_list(args)
        print(json.dumps(jobs, indent=2))
    elif args.subcommand == "dlq":
        if args.action=="list":
            dlq = cmd_dlq_list(args)
            print(json.dumps(dlq, indent=2))
        elif args.action=="retry":
            cmd_requeue_dlq(args)
    
    elif args.subcommand=="retry-job":
        cmd_retry_job(args)
    
    elif args.subcommand =="status":
        cmd_status(args)
    else:
        parser.print_help()

if __name__ == "__main__":
    main()



