#!/usr/bin/env python3
from logger import get_logger
from models import get_conn
from jobs import enqueue_job,list_jobs,show_job,dlq_list,requeue_dlq,retry_job_force,worker_loop
import json  
import sys  
from multiprocessing import Process, Event
import time  
import argparse


logging = get_logger()


def cmd_enqueue(args):
    job_id = enqueue_job(args.db,logging,command=args.command, job_json=args.json, max_retries=args.max_retries)
    print(job_id)

def cmd_list(args):
    rows = list_jobs(args.db,logging=logging,state=args.state, limit=args.limit)
    print(json.dumps(rows, indent=2, default=str))

def cmd_show(args):
    job = show_job(args.db, args.job_id)
    if not job:
        print(f"Job {args.job_id} not found", file=sys.stderr)
        sys.exit(2)
    print(json.dumps(job, indent=2, default=str))

def cmd_dlq_list(args):
    rows = dlq_list(args.db, logger=logging,limit=args.limit)
    print(json.dumps(rows, indent=2, default=str))

def cmd_requeue_dlq(args):
    try:
        requeue_dlq(args.db,logging, args.job_id)
        print(f"Requeued {args.job_id}")
    except Exception as e:
        print(f"Error: {e}", file=sys.stderr)
        sys.exit(2)

def cmd_retry_job(args):
    try:
        retry_job_force(args.db,logging, args.job_id)
        print(f"Retry scheduled for {args.job_id}")
    except Exception as e:
        print(f"Error: {e}", file=sys.stderr)
        sys.exit(2)

def cmd_start_workers(args):
    # spawn worker processes and handle SIGINT to stop them
    stop_event = Event()
    processes = []
    logging.info(f"Starting {args.count} worker(s) (db={args.db})")
    try:
        for i in range(args.count):
            p = Process(target=worker_loop, args=(args.db, logging,stop_event, i, args.poll_interval), name=f"worker-{i}")
            p.start()
            processes.append(p)
        # main process waits until terminated
        while True:
            alive = any(p.is_alive() for p in processes)
            if not alive:
                break
            time.sleep(0.5)
    except KeyboardInterrupt:
        logging.info("Shutdown requested, stopping workers...")
        stop_event.set()
        # give grace time
        for p in processes:
            p.join(timeout=5)
        logging.info("All workers stopped gracefully.")


def main():
    parser = argparse.ArgumentParser(description="queuectl - simple background job queue")
    subparsers = parser.add_subparsers(dest="subcommand")

    # Enqueue
    enqueue_parser = subparsers.add_parser("enqueue", help="Enqueue a new job")
    enqueue_parser.add_argument("--db", default="./queue.db", help="Path to queue database file")
    enqueue_parser.add_argument("--command", help="Command to run")
    enqueue_parser.add_argument("--max-retries", type=int, default=3, help="Max retries per job")
    enqueue_parser.add_argument("--json",help="Loads Json")

    # Start workers

    worker_parser = subparsers.add_parser("worker", help="Manage worker processes")
    worker_subparsers = worker_parser.add_subparsers(dest="action", required=True)
    worker_start_parser = worker_subparsers.add_parser("start", help="Start worker processes")
    worker_start_parser.add_argument("--count", type=int, default=2, help="Number of worker processes")
    worker_start_parser.add_argument("--poll-interval", type=int, default=2, help="Polling interval (seconds)")
    worker_start_parser.add_argument("--db", default="./queue.db", help="Path to queue database file")
    

    # List jobs
    list_parser = subparsers.add_parser("list", help="List all jobs")
    list_parser.add_argument("--db", default="./queue.db", help="Path to queue database file")
    list_parser.add_argument("--state", default="running", help="Path to queue database file")
    list_parser.add_argument("--limit", default=10, help="Path to queue database file")

    # Dead Letter Queue
    dlq_parser = subparsers.add_parser("dlq", help="Show Dead Letter Queue")
    dlq_parser.add_argument("--db", default="./queue.db", help="Path to queue database file")
    dlq_parser.add_argument("--limit", default=10, help="Path to queue database file")


    retry_parser= subparsers.add_parser("retry-job")
    retry_parser.add_argument("--db", default="./queue.db", help="Path to queue database file")
    retry_parser.add_argument("--job-id",default=0,help="The Job Id of the corresponding job")

    args = parser.parse_args()

    # Dispatch
    if args.subcommand == "enqueue":
        print(args.command)
        enqueue_job(db_path=args.db,logger=logging,command=args.command, max_retries=args.max_retries,job_json=args.json)
    elif args.subcommand == "worker":
        cmd_start_workers(args)
    elif args.subcommand == "list":
        jobs = cmd_list(args)
        print(json.dumps(jobs, indent=2))
    elif args.subcommand == "dlq":
        dlq = cmd_dlq_list(args)
        print(json.dumps(dlq, indent=2))
    
    elif args.subcommand=="retry-job":
        cmd_retry_job(args)
    else:
        parser.print_help()

if __name__ == "__main__":
    main()



